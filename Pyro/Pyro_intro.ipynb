{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "from pyro.distributions import Normal\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "# for CI testing\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 100  # size of toy data\n",
    "\n",
    "def build_linear_dataset(N, p=50, noise_std=0.5):\n",
    "    X = np.random.rand(N, p)\n",
    "    # w = 3\n",
    "    w = 3 * np.ones(p)\n",
    "    # b = 1\n",
    "    y = np.dot(X**2, w)  + np.random.normal(0, noise_std, size=N)\n",
    "    y = y.reshape(N, 1)\n",
    "    X, y = torch.tensor(X).type(torch.Tensor), torch.tensor(y).type(torch.Tensor)\n",
    "    data = torch.cat((X, y), 1)\n",
    "    assert data.shape == (N, p + 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a12bd7da0>]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAG0tJREFUeJzt3WlwHPd55/HvM5jBRYK4wQuEQErU\nbZOUIFpnIkt2JDuOpVSklF22l5uVozdJyqnNliNnX+xma1Nrv7GTrdraWpXthFU+Fdk6SpWyTctS\n5MQyKVDUwUMUxZsEiZM4CTTmePbFNIYURYggOQNMN3+fKlRP9/RMPw30PP2fp/+Nv7k7IiISfYmF\nDkBERIpDCV1EJCaU0EVEYkIJXUQkJpTQRURiQgldRCQmlNBFRGJiTgndzBrM7Gkze8fM9pjZHWbW\nZGZbzGxfOG0sdbAiIjK7ubbQ/wH4mbtfD6wD9gBPAC+6+1rgxXBeREQWiF3oTlEzWwK8Cazxs1Y2\ns73Ave5+wsyWAy+7+3Uf9l4tLS3e2dl5+VGLiFxBtm/fPuDurRdaLzmH91oD9AP/aGbrgO3AV4Cl\n7n4CIEzqbed7sZk9DjwO0NHRQXd39xx3QUREAMzs8FzWm0vJJQncAvxfd98ATHAR5RV3f9Ldu9y9\nq7X1gicYERG5RHNJ6MeAY+6+NZx/mnyC7w1LLYTTvtKEKCIic3HBhO7uJ4GjZjZTH78f2A08D2wK\nl20CnitJhCIiMidzqaED/AXwfTOrBA4Af0L+ZPCUmT0GHAEeLU2IIiIyF3NK6O7+BtB1nqfuL244\nIiJyqXSnqIhITCihi4jEhBK6iEgJvXNylG/+Yi8D40HJt6WELiJSQu+cGON//+o9RifTJd+WErqI\nSAkFmSwAVamKkm9LCV1EpISCTA6AqmTp060SuohICQVpJXQRkViYzs4kdJVcREQiLUhnMYNUhZV8\nW0roIiIlFGRyVCUTmCmhi4hEWj6hl77cAkroIiIlFWSy83JBFJTQRURKKkjnqEopoYuIRJ5KLiIi\nMaGSi4hITMz0cpkPSugiIiUUpFVyERGJhSCT1UVREZE4UMlFRCQmgkyOSpVcRESiL0irl4uISCyo\n5CIiEhO6sUhEJCbUy0VEJAayOSed9XkruSTnspKZHQLGgCyQcfcuM2sCfgx0AoeAP3b3U6UJU0Qk\neqYz8zdaEVxcC/3j7r7e3bvC+SeAF919LfBiOC8iIqEgkwXmZzxRuLySy0PA5vDxZuDhyw9HRCQ+\nCi30MquhO/ALM9tuZo+Hy5a6+wmAcNpWigBFRKIqmOeSy5xq6MBd7t5jZm3AFjN7Z64bCE8AjwN0\ndHRcQogiItFUliUXd+8Jp33AM8BGoNfMlgOE075ZXvuku3e5e1dra2txohYRiYCp9EwLvUwSupkt\nMrO6mcfA7wE7geeBTeFqm4DnShWkiEgUFUouqfIpuSwFnjGzmfV/4O4/M7PXgKfM7DHgCPBo6cIU\nEYme+S65XDChu/sBYN15lg8C95ciKBGRODhzUbRMSi4iInJpgnT53lgkIiIXoVByKbN+6CIicpFU\nchERiYn5vrFICV1EpESCdL7kUqkWuohItKnkIiISE0roIiIxEWSyVCYThDdmlpwSuohIiQTp+Rsg\nGpTQRURKZj4HiAYldBGRkgkyWbXQRUTiIMjk5u0uUVBCFxEpmXwNXSUXEZHIm87qoqiISCwEadXQ\nRURiIV9DV8lFRCTy8t0W1UIXEYk8dVsUEYkJ9XIREYkJ9UMXEYkJlVxERGJC/8tFRCQG3J1p9XIR\nEYm+mcEt5mv4OVBCFxEpifkerQiU0EVESiLI5AeILss7Rc2swsx2mNkL4fxqM9tqZvvM7MdmVlm6\nMEVEoiVIl3cL/SvAnrPmvwF8y93XAqeAx4oZmIhIlJVtycXM2oHfB74dzhtwH/B0uMpm4OFSBCgi\nEkWFkksZdlv8e+CrQC6cbwaG3T0Tzh8DVp7vhWb2uJl1m1l3f3//ZQUrIhIVhRZ6Od0pamafAfrc\nffvZi8+zqp/v9e7+pLt3uXtXa2vrJYYpIhItC1FDT85hnbuAz5rZp4FqYAn5FnuDmSXDVno70FO6\nMEVEoqUsSy7u/jV3b3f3TuBzwK/c/QvAS8Aj4WqbgOdKFqWISMSU7UXRWfw18J/N7D3yNfXvFCck\nEZHomw4TevU81tDnUnIpcPeXgZfDxweAjcUPSUQk+s600Muo5CIiIhfvTA09GiUXERGZxZleLmqh\ni4hEWln2QxcRkYs3U3KprFBCFxGJtCCTo7IiQSJxvvswS0MJXUSkBIL0/I5WBEroIiIlEWSy81o/\nByV0EZGSmCm5zCcldBGREggyuXkdrQiU0EVESiJIZ1VDFxGJgyCji6IiIrEQZLLzepcoKKGLiJRE\nvoauFrqISOSpH7qISEyo5CIiEhO6KCoiEhOqoYuIxES+H7pKLiIikTedVclFRCTy3F01dBGROEhn\nHXf0v1xERKJuIQaIBiV0EZGiK4wnqoQuIhJtZxK6Si4iIpEWpMOSS7n1QzezajPbZmZvmtkuM/vb\ncPlqM9tqZvvM7MdmVln6cEVEyl85l1wC4D53XwesBx40s9uBbwDfcve1wCngsdKFKSISHTMJvbLc\nErrnjYezqfDHgfuAp8Plm4GHSxKhiEjEFEou5VhDN7MKM3sD6AO2APuBYXfPhKscA1aWJkQRkWgp\n55IL7p519/VAO7ARuOF8q53vtWb2uJl1m1l3f3//pUcqIhIRkejl4u7DwMvA7UCDmSXDp9qBnlle\n86S7d7l7V2tr6+XEKiISCYUbi8qwl0urmTWEj2uATwB7gJeAR8LVNgHPlSpIEZEoCdILU3JJXngV\nlgObzayC/AngKXd/wcx2Az8ys/8J7AC+U8I4RUQiY6FKLhdM6O7+FrDhPMsPkK+ni4jIWfS/XERE\nYqLQQi+3GrqIiFycmRp6ZYUSuohIpAWZLMmEkVRCFxGJtoUYrQiU0EVEim46k5v30YpACV1EpOiC\nTFYtdBGROFDJRUQkJoJ0bt5vKgIldBGRogsy2Xnvgw5K6CIiRaeSi4hITOQTukouIiKRF2Sy8z78\nHCihi4gUXf6iqBK6iEjkqYYuIhIT+RuLVEMXEYm8IJNTt0URkThQDV1EJAbcXSUXEZE4yOScnM//\n8HOghC4iUlQLNfwcKKGLiBRVkJ4ZIFolFxGRSCu00FVyERGJNpVcRERiYrrQQlfJRUQk0oLMTA1d\nLXQRkUgLyrmFbmarzOwlM9tjZrvM7Cvh8iYz22Jm+8JpY+nDFREpb0G6vGvoGeCv3P0G4Hbgz8zs\nRuAJ4EV3Xwu8GM6LiFzRyrrk4u4n3P318PEYsAdYCTwEbA5X2ww8XKogRUSioqxLLmczs05gA7AV\nWOruJyCf9IG2WV7zuJl1m1l3f3//5UUrIlLmyrqFPsPMFgM/Af7S3Ufn+jp3f9Ldu9y9q7W19VJi\nFBGJjJkaetkOQWdmKfLJ/Pvu/tNwca+ZLQ+fXw70lSZEEZHoKOs7Rc3MgO8Ae9z9m2c99TywKXy8\nCXiu+OGJiERLoeSSmv8aenIO69wFfAl428zeCJf9DfB14Ckzeww4AjxamhBFRKKj0G1xAVroF0zo\n7v5vgM3y9P3FDUdEJNqCTI6EQTIxW9osHd0pKiJSRDOjFeWr1fNLCV1EpIgWaoBoUEIXESmqhRog\nGpTQRUSKaqEGiAYldBGRogoyaqGLiMSCaugiIjGhkouISEzooqiISExMZ5XQRURiId9CV8lFRCTy\ngkxWF0VFROJA3RZFRGIin9BVchERibwgnVULXUQkDoJMbkGGnwMldBGRoslkc2RyrpKLiEjUTWfD\n0YrUy0VEJNoWcvg5UEIXESmaIDOT0FVyERGJtCCTBdRCFxGJvEILXTV0EZFoO1NDV8lFRCTSVHIR\nEYmJMxdFldBFRCKt0EJPlWnJxcy+a2Z9ZrbzrGVNZrbFzPaF08bShikiUv6i0A/9n4AHz1n2BPCi\nu68FXgznRUSuaGVfcnH3V4ChcxY/BGwOH28GHi5yXCIikVP2JZdZLHX3EwDhtK14IYmIRNN0ubfQ\nL5eZPW5m3WbW3d/fX+rNiYgsmLIvucyi18yWA4TTvtlWdPcn3b3L3btaW1svcXMiIuUvqv/L5Xlg\nU/h4E/BcccIREYmuIJ3FDFIVtiDbn0u3xR8CrwLXmdkxM3sM+DrwSTPbB3wynBcRuaLNDBBttjAJ\nPXmhFdz987M8dX+RYxERibQgk6OyYuHu19SdoiIiRRJksgvWZRGU0EVEiiZI5xashwsooYuIFM1M\nDX2hKKGLiBRJkMkuWJdFUEIXESmaIJNbsNGKQAldRKRoVEMXEYkJlVxERGJCF0VFRGIiX0NXC11E\nJPKCdFYtdBGROFDJRUQkJvIJXSUXEZHIy/8vF7XQRUQiLZdz0llXyUVEJOqmsws7WhEooYuIFEWQ\nXtjxREEJXUSkKIJMFkA1dBGRqFvoAaJBCV1EpChmWuiVKrmIiETblGroIiLxcKbkooQuIhJphYui\nqqGLiERboYWuXi4iItGmfugiclHcfaFDiJ1MNsd02Lq+HOVQcklezovN7EHgH4AK4Nvu/vWiRFUG\nMtkcv943wC/39DI4Ps3oVJqRyXR+ejrNVDrH3WtbeOTWdu6/oW3WP+KB/nGefaOHn+88SXUqwTVt\ndVzTtpi1bYtZu3Qx7Y21ZHI5jgye5uDABIcGJzg4cJrDgxPk3GleVEXTokqaFlXSvDg/rUpWkA4P\nwulwms7mWFyV5KYV9axduphUxfnP1elsjr0nx9hxdJijQ6dJmJGqMCoSRqoiQTJhNNSmeOCmZTTU\nVl7w9+TuHB+eZHl9DRUJ+9B1D/SP8/2tR3h2x3Gqkgk6mmvpbF5UmF7VXMs1bYvn9IE4OTLFL/f0\nknNn4+omrm2rIzHL9t2dgwMTvHZoiGwO/mDdcuqqUxfcxvnkcs6xU5P0jwfcvHLJZX14cznn9SOn\nGD6dJutOLudk3cnm8j+D49OcGJni5OhkfjoyRd9YwE0rlvCn96zhUzcvIznL3zmXc/51Xz/fe/Uw\no1NpPra6mTuvbuaWqxqpLvEADONBhh9tO8K/vtvPnVe38PCGFSyvrynpNi/GeJBhx5FTdB86Rffh\nIXYcGSbI5LiqqZa1Sxdz7dL8Z/TapXWsaKjBznNYVVYkPvB7LIeLonapZ3wzqwDeBT4JHANeAz7v\n7rtne01XV5d3d3df0vbmy96TY/zk9WM8s+M4/WMBddVJltdXs6Q6RX1N/mdJTT4Z/GznSU6OTtFQ\nm+KhdSt45NZV3LxyCYMT07zwZg/PvNHDm0eHMYPbVzdTkTD29Y3ROxoUtleZTJDO5jj7z9BYm6Kz\nZRHJhDE4Mc3QxDTDp9Nz3ofKigTXL6/jphX13LxyCYurkrx1bIQ3jg6z8/jI+w48J3/yyp1zGFQl\nE3zmoyv44u0drF/VgJ1zVB8dOs0zO47zzI7jHByYoL4mxd1rW/jdta38zrWtLKuvBvInkF/u7uV7\nWw/z7+8NkkwYn7xxKTWpCg4P5U9cA+PThfetTiW4rbOJ29fkE9BHVtYXktahgQl+vuskP9t1kh1H\nht8XT31Nits6m9i4upGNq5tJVRivHRxi26Ehth08xcD4md/5osoK/ujWdv7DHZ1c07Z41t9j7+gU\nbx0bYV/fGPt6x9nXN8Z7feOF7mk1qQruuqaFj1/fyr3XtbGyYW5Jq29sin/uPsYPtx3h2KnJD123\nJlXB8oZqltdXs2xJDc2LK9myu5eDAxOsaqrhy3ev4dGudmor822z8SDDT7YfY/NvDnFgYILWuipW\n1Ffz9vERcp4/NjZ0NHDH1c1c1VzLqYk0QxPTDE5Mcyo81ioSxsfWNHHn1S2sX9Uw537VfaNT/ONv\nDvH93x5mdCrDqqYajg5NFo7/P7xlJZ+6edmcTqbuzru947zybj+/PTAIQH1tioaaShprUzTUpqiv\nrWRNyyKuXVr3oTGOTKbZdnCIV/cPsu3QILt7Rsk5JAyuX7aE2zobqatO5f/OfeMcHjxN9twPxHnU\nVSdprauira6K1rpq+sem+O2BIbb91/tpq6ue0+9srsxsu7t3XXC9y0jodwD/3d0fCOe/BuDu/2u2\n11xqQn/ylf0cHDgdHtTVLKs/85NKJDg+PEnP8OSZ6alJTp2enokTg8JZNplIsLg6SV11krrqFEvC\nx+NBlmd3HOft4yMkE8Z917fxyK3t3Htd26wHSzbn/Nt7Azy9/Rg/33WS6UyOVU019AxPkc05Ny5f\nwh9uWMkfrFtRSHCQP8De6xtnf9847/WPU52qYHVLvpW6umXReVvGmWyOU6fTDE4ETGdyVCYTVFYk\nSFUkqEomqEwmGJyYZlfPKLuOj7CzZ4Sdx0cZmcyfCKqSCT6ysp71qxpYt6qB9asaaG+sKSTqXM5J\n53JksvnW7A+35VvSE9NZblqxhC987Cruu76Nl/f28dPXj7Pt0BAAt69p4hM3LOWdk2O88m4/fWP5\nxHnd0jrWr2rg5Xf76B0NWNlQw+c3ruKPb1v1gYN9PMhweHCCgwMTdB86xW8PDPLOyTEAFlclua2z\nkRMjU4VlH1lZzwM3LeWBm5ZRnapg28Gh/M+hIQ4OTLzvvVc21LBxdRMbVzdxW2cTE0GGza8e4oU3\nTzCdzXHP2hb+452d3HVNC7t6Rtlx5BQ7jg6z4/ApekamCu+zvL660Gpb27aYhtoUv9k/yK/e6Ssk\n5euW1nHP2hZWty4qJOAVDdXU16Rwh3/fP8APth5hy+5eMjnnzqub+dzGDjqba0lY/ltSRcIKj5sW\nVbKkOvmBk2k252zZ3cuTr+zn9SPDNNSm+NLtVzERZPnn7qOMBRnWrWrgP93VyaduXk5lMsHYVJrX\nDuWT2qsHBtnVM1poRCSMwrfAxtpKJqYzhednTrB3XN3M+lUN1FWlqKlMUJWsoKaygupUBT3Dk3z7\n1wd4dkcPmVyOB29exp/es4YNHY0cHpwonPgPD56mKpng/hvaWNOymObFlTQvrqJlUX66qKqC148M\n88q7/fx6X3+h4bOmdRHVyQpGJtMMn55mYjr7vt/HTAPmIyvr+Wh7PTetqGdoYprf7B/k1f0DhZNZ\nVTLBLR2N3NbZSFdnExs6Gs57cgkyWQ70T7Cvb5y+0akPPJ9fJ0f/WEDf2FQ4DegbzTcAX/nqx4v+\nLWg+EvojwIPu/uVw/kvAx9z9z2d7zaUm9L9++q186WNi+oLrJgyWLammeXEVAI4XDlx3yORyjE9l\nGJ3KMB5k3vfaG5cv4ZFb23lo/YrC6+dqZDLNC2/1sGV3LzcsX8LD61dy3bK6i3qPYnPPlwfGgwzX\ntM1ehpnNeJDh2R3H+d5vDxeSKeQ/YH90S/731N5Y+77tzST2V/b1s+PIMBtXN/HFj13Fx69vu2BJ\n5mwD4wFbDwzxm/0DbDs4ROOiSh64aRkP3LT0fds8V9/YFK8dPEU6m6Ors3HWdQfGA3649Qjf23r4\nfd+YIH8S2NDRwC0djaxbVc+1S+tmbVW6O/v7J3h5bx8v7e1j28Eh0tn3f6aqUwlqK5MMTUzTWJvi\nkVvb+fzGDta0zv7tYK66Dw3x/145wJbdvSQTxqc/spw/uauTDR2NH/q6kdNpBiYCmhdVsqQ69YFy\n1cjpNFsPDoZJcZC9vWOzvFNeVTLBo13tfPnuNXS2LPrA8+7OjqPDPPP6cbbs7qVvbOoD3wpn1Nek\nuPuaFn7n2hbuWdvKinO++UxncoxMpjl1epp3e8d4+9gIbx0bYefxEcbO+kynKoz1qxq44+oW7ry6\nmQ0dDSWvb+dyPmvp73LMR0J/FHjgnIS+0d3/4pz1HgceB+jo6Lj18OHDl7Q9yJ85+0aDsK44xcmR\nSdJZZ0VDNSsbalnRkG/Bz1ZXPFc254wHGcam0rjDqqbZE8WVzN15/cgwr+4f4J61rXy0vf4Drcao\nSmdz/GznSfaeHOPmlfXc0tFA25JL/7qcyeboHw8KNe8TI1OcGJ5k6PQ0v3tta+FbRbEdO3WaymSi\n6F/1Z/SPBew9OcZkOstkOstU+DM5naUymeCz6y6uEZTLOcOTaQbHAwbGw7Li5DQ3Ll/CR9sbLurk\nf/Z7Hh46zc7jIyypSXFbZ2OhFBV1sSq5iIhcyeaa0C/ncuxrwFozW21mlcDngOcv4/1EROQyXPL3\nEXfPmNmfAz8n323xu+6+q2iRiYjIRbmsApO7/wvwL0WKRURELoPuFBURiQkldBGRmFBCFxGJCSV0\nEZGYUEIXEYmJS76x6JI2ZtYPXOqtoi3AQBHDiQLt85VB+xx/l7u/V7l764VWmteEfjnMrHsud0rF\nifb5yqB9jr/52l+VXEREYkIJXUQkJqKU0J9c6AAWgPb5yqB9jr952d/I1NBFROTDRamFLiIiHyIS\nCd3MHjSzvWb2npk9sdDxlIKZfdfM+sxs51nLmsxsi5ntC6cfPgxNhJjZKjN7ycz2mNkuM/tKuDzO\n+1xtZtvM7M1wn/82XL7azLaG+/zj8N9Rx4qZVZjZDjN7IZyP9T6b2SEze9vM3jCz7nBZyY/tsk/o\n4WDU/wf4FHAj8Hkzu3FhoyqJfwIePGfZE8CL7r4WeDGcj4sM8FfufgNwO/Bn4d81zvscAPe5+zpg\nPfCgmd0OfAP4VrjPp4DHFjDGUvkKsOes+Sthnz/u7uvP6q5Y8mO77BM6sBF4z90PuPs08CPgoQWO\nqejc/RVg6JzFDwGbw8ebgYfnNagScvcT7v56+HiM/Id9JfHeZ3f38XA2Ff44cB/wdLg8VvsMYGbt\nwO8D3w7njZjv8yxKfmxHIaGvBI6eNX8sXHYlWOruJyCfAIG2BY6nJMysE9gAbCXm+xyWHt4A+oAt\nwH5g2N1nRjeO4/H998BXgVw430z899mBX5jZ9nBcZZiHYzsKI6ieb7RYdc2JCTNbDPwE+Et3H43L\n4NOzcfcssN7MGoBngBvOt9r8RlU6ZvYZoM/dt5vZvTOLz7NqbPY5dJe795hZG7DFzN6Zj41GoYV+\nDFh11nw70LNAscy3XjNbDhBO+xY4nqIysxT5ZP59d/9puDjW+zzD3YeBl8lfP2gws5nGVdyO77uA\nz5rZIfLl0vvIt9jjvM+4e0847SN/4t7IPBzbUUjoV/Jg1M8Dm8LHm4DnFjCWogrrqN8B9rj7N896\nKs773Bq2zDGzGuAT5K8dvAQ8Eq4Wq31296+5e7u7d5L/7P7K3b9AjPfZzBaZWd3MY+D3gJ3Mw7Ed\niRuLzOzT5M/qM4NR/90Ch1R0ZvZD4F7y/5WtF/hvwLPAU0AHcAR41N3PvXAaSWZ2N/Br4G3O1Fb/\nhnwdPa77/FHyF8MqyDemnnL3/2Fma8i3XpuAHcAX3T1YuEhLIyy5/Bd3/0yc9znct2fC2STwA3f/\nOzNrpsTHdiQSuoiIXFgUSi4iIjIHSugiIjGhhC4iEhNK6CIiMaGELiISE0roIiIxoYQuIhITSugi\nIjHx/wF5G7/5u5ffkwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11139f470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = build_linear_dataset(N)\n",
    "data.shape\n",
    "plt.plot(data.numpy()[2][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class  RegressionModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        # p = number of features\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(p, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        a = self.linear(x)\n",
    "        return torch.sigmoid(a)\n",
    "\n",
    "regression_model = RegressionModel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0050] loss: 20531.9844\n",
      "[iteration 0100] loss: 20531.2637\n",
      "[iteration 0150] loss: 20531.0547\n",
      "[iteration 0200] loss: 20530.9355\n",
      "[iteration 0250] loss: 20530.8809\n",
      "[iteration 0300] loss: 20530.8516\n",
      "[iteration 0350] loss: 20530.8281\n",
      "[iteration 0400] loss: 20530.8105\n",
      "[iteration 0450] loss: 20530.7969\n",
      "[iteration 0500] loss: 20530.7734\n",
      "[iteration 0550] loss: 20530.7598\n",
      "[iteration 0600] loss: 20530.7559\n",
      "[iteration 0650] loss: 20530.7539\n",
      "[iteration 0700] loss: 20530.7500\n",
      "[iteration 0750] loss: 20530.7500\n",
      "[iteration 0800] loss: 20530.7480\n",
      "[iteration 0850] loss: 20530.7441\n",
      "[iteration 0900] loss: 20530.7422\n",
      "[iteration 0950] loss: 20530.7383\n",
      "[iteration 1000] loss: 20530.7402\n",
      "[iteration 1050] loss: 20530.7344\n",
      "[iteration 1100] loss: 20530.7324\n",
      "[iteration 1150] loss: 20530.7305\n",
      "[iteration 1200] loss: 20530.7285\n",
      "[iteration 1250] loss: 20530.7266\n",
      "[iteration 1300] loss: 20530.7246\n",
      "[iteration 1350] loss: 20530.7266\n",
      "[iteration 1400] loss: 20530.7246\n",
      "[iteration 1450] loss: 20530.7188\n",
      "[iteration 1500] loss: 20530.7188\n",
      "[iteration 1550] loss: 20530.7168\n",
      "[iteration 1600] loss: 20530.7168\n",
      "[iteration 1650] loss: 20530.7168\n",
      "[iteration 1700] loss: 20530.7168\n",
      "[iteration 1750] loss: 20530.7148\n",
      "[iteration 1800] loss: 20530.7148\n",
      "[iteration 1850] loss: 20530.7129\n",
      "[iteration 1900] loss: 20530.7129\n",
      "[iteration 1950] loss: 20530.7148\n",
      "[iteration 2000] loss: 20530.7148\n",
      "[iteration 2050] loss: 20530.7148\n",
      "[iteration 2100] loss: 20530.7148\n",
      "[iteration 2150] loss: 20530.7148\n",
      "[iteration 2200] loss: 20530.7148\n",
      "[iteration 2250] loss: 20530.7168\n",
      "[iteration 2300] loss: 20530.7168\n",
      "[iteration 2350] loss: 20530.7168\n",
      "[iteration 2400] loss: 20530.7148\n",
      "[iteration 2450] loss: 20530.7168\n",
      "[iteration 2500] loss: 20530.7168\n",
      "[iteration 2550] loss: 20530.7168\n",
      "[iteration 2600] loss: 20530.7168\n",
      "[iteration 2650] loss: 20530.7188\n",
      "[iteration 2700] loss: 20530.7188\n",
      "[iteration 2750] loss: 20530.7188\n",
      "[iteration 2800] loss: 20530.7188\n",
      "[iteration 2850] loss: 20530.7188\n",
      "[iteration 2900] loss: 20530.7227\n",
      "[iteration 2950] loss: 20530.7207\n",
      "[iteration 3000] loss: 20530.7207\n",
      "[iteration 3050] loss: 20530.7207\n",
      "[iteration 3100] loss: 20530.7207\n",
      "[iteration 3150] loss: 20530.7207\n",
      "[iteration 3200] loss: 20530.7188\n",
      "[iteration 3250] loss: 20530.7188\n",
      "[iteration 3300] loss: 20530.7168\n",
      "[iteration 3350] loss: 20530.7168\n",
      "[iteration 3400] loss: 20530.7188\n",
      "[iteration 3450] loss: 20530.7188\n",
      "[iteration 3500] loss: 20530.7188\n",
      "[iteration 3550] loss: 20530.7188\n",
      "[iteration 3600] loss: 20530.7188\n",
      "[iteration 3650] loss: 20530.7207\n",
      "[iteration 3700] loss: 20530.7207\n",
      "[iteration 3750] loss: 20530.7207\n",
      "[iteration 3800] loss: 20530.7188\n",
      "[iteration 3850] loss: 20530.7188\n",
      "[iteration 3900] loss: 20530.7188\n",
      "[iteration 3950] loss: 20530.7188\n",
      "[iteration 4000] loss: 20530.7188\n",
      "[iteration 4050] loss: 20530.7188\n",
      "[iteration 4100] loss: 20530.7188\n",
      "[iteration 4150] loss: 20530.7188\n",
      "[iteration 4200] loss: 20530.7188\n",
      "[iteration 4250] loss: 20530.7207\n",
      "[iteration 4300] loss: 20530.7207\n",
      "[iteration 4350] loss: 20530.7207\n",
      "[iteration 4400] loss: 20530.7207\n",
      "[iteration 4450] loss: 20530.7207\n",
      "[iteration 4500] loss: 20530.7207\n",
      "[iteration 4550] loss: 20530.7207\n",
      "[iteration 4600] loss: 20530.7207\n",
      "[iteration 4650] loss: 20530.7207\n",
      "[iteration 4700] loss: 20530.7207\n",
      "[iteration 4750] loss: 20530.7207\n",
      "[iteration 4800] loss: 20530.7207\n",
      "[iteration 4850] loss: 20530.7207\n",
      "[iteration 4900] loss: 20530.7188\n",
      "[iteration 4950] loss: 20530.7188\n",
      "[iteration 5000] loss: 20530.7188\n",
      "[iteration 5050] loss: 20530.7188\n",
      "[iteration 5100] loss: 20530.7188\n",
      "[iteration 5150] loss: 20530.7188\n",
      "[iteration 5200] loss: 20530.7188\n",
      "[iteration 5250] loss: 20530.7188\n",
      "[iteration 5300] loss: 20530.7188\n",
      "[iteration 5350] loss: 20530.7188\n",
      "[iteration 5400] loss: 20530.7188\n",
      "[iteration 5450] loss: 20530.7188\n",
      "[iteration 5500] loss: 20530.7188\n",
      "[iteration 5550] loss: 20530.7188\n",
      "[iteration 5600] loss: 20530.7188\n",
      "[iteration 5650] loss: 20530.7188\n",
      "[iteration 5700] loss: 20530.7188\n",
      "[iteration 5750] loss: 20530.7188\n",
      "[iteration 5800] loss: 20530.7188\n",
      "[iteration 5850] loss: 20530.7188\n",
      "[iteration 5900] loss: 20530.7188\n",
      "[iteration 5950] loss: 20530.7188\n",
      "[iteration 6000] loss: 20530.7188\n",
      "[iteration 6050] loss: 20530.7188\n",
      "[iteration 6100] loss: 20530.7188\n",
      "[iteration 6150] loss: 20530.7188\n",
      "[iteration 6200] loss: 20530.7188\n",
      "[iteration 6250] loss: 20530.7188\n",
      "[iteration 6300] loss: 20530.7188\n",
      "[iteration 6350] loss: 20530.7188\n",
      "[iteration 6400] loss: 20530.7188\n",
      "[iteration 6450] loss: 20530.7188\n",
      "[iteration 6500] loss: 20530.7188\n",
      "[iteration 6550] loss: 20530.7188\n",
      "[iteration 6600] loss: 20530.7188\n",
      "[iteration 6650] loss: 20530.7188\n",
      "[iteration 6700] loss: 20530.7188\n",
      "[iteration 6750] loss: 20530.7188\n",
      "[iteration 6800] loss: 20530.7188\n",
      "[iteration 6850] loss: 20530.7188\n",
      "[iteration 6900] loss: 20530.7188\n",
      "[iteration 6950] loss: 20530.7188\n",
      "[iteration 7000] loss: 20530.7188\n",
      "[iteration 7050] loss: 20530.7188\n",
      "[iteration 7100] loss: 20530.7188\n",
      "[iteration 7150] loss: 20530.7188\n",
      "[iteration 7200] loss: 20530.7188\n",
      "[iteration 7250] loss: 20530.7188\n",
      "[iteration 7300] loss: 20530.7188\n",
      "[iteration 7350] loss: 20530.7188\n",
      "[iteration 7400] loss: 20530.7188\n",
      "[iteration 7450] loss: 20530.7188\n",
      "[iteration 7500] loss: 20530.7188\n",
      "[iteration 7550] loss: 20530.7188\n",
      "[iteration 7600] loss: 20530.7188\n",
      "[iteration 7650] loss: 20530.7188\n",
      "[iteration 7700] loss: 20530.7188\n",
      "[iteration 7750] loss: 20530.7188\n",
      "[iteration 7800] loss: 20530.7188\n",
      "[iteration 7850] loss: 20530.7188\n",
      "[iteration 7900] loss: 20530.7188\n",
      "[iteration 7950] loss: 20530.7188\n",
      "[iteration 8000] loss: 20530.7188\n",
      "[iteration 8050] loss: 20530.7188\n",
      "[iteration 8100] loss: 20530.7188\n",
      "[iteration 8150] loss: 20530.7188\n",
      "[iteration 8200] loss: 20530.7188\n",
      "[iteration 8250] loss: 20530.7188\n",
      "[iteration 8300] loss: 20530.7188\n",
      "[iteration 8350] loss: 20530.7188\n",
      "[iteration 8400] loss: 20530.7207\n",
      "[iteration 8450] loss: 20530.7207\n",
      "[iteration 8500] loss: 20530.7207\n",
      "[iteration 8550] loss: 20530.7207\n",
      "[iteration 8600] loss: 20530.7207\n",
      "[iteration 8650] loss: 20530.7207\n",
      "[iteration 8700] loss: 20530.7207\n",
      "[iteration 8750] loss: 20530.7207\n",
      "[iteration 8800] loss: 20530.7207\n",
      "[iteration 8850] loss: 20530.7207\n",
      "[iteration 8900] loss: 20530.7207\n",
      "[iteration 8950] loss: 20530.7207\n",
      "[iteration 9000] loss: 20530.7207\n",
      "[iteration 9050] loss: 20530.7207\n",
      "[iteration 9100] loss: 20530.7207\n",
      "[iteration 9150] loss: 20530.7207\n",
      "[iteration 9200] loss: 20530.7207\n",
      "[iteration 9250] loss: 20530.7207\n",
      "[iteration 9300] loss: 20530.7207\n",
      "[iteration 9350] loss: 20530.7207\n",
      "[iteration 9400] loss: 20530.7207\n",
      "[iteration 9450] loss: 20530.7207\n",
      "[iteration 9500] loss: 20530.7207\n",
      "[iteration 9550] loss: 20530.7207\n",
      "[iteration 9600] loss: 20530.7207\n",
      "[iteration 9650] loss: 20530.7207\n",
      "[iteration 9700] loss: 20530.7207\n",
      "[iteration 9750] loss: 20530.7207\n",
      "[iteration 9800] loss: 20530.7207\n",
      "[iteration 9850] loss: 20530.7207\n",
      "[iteration 9900] loss: 20530.7207\n",
      "[iteration 9950] loss: 20530.7207\n",
      "[iteration 10000] loss: 20530.7207\n",
      "Learned parameters:\n",
      "linear.weight: 10.410\n",
      "linear.bias: 14.036\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "optim = torch.optim.Adam(regression_model.parameters(), lr=0.05)\n",
    "num_iterations = 10000 if not smoke_test else 2\n",
    "\n",
    "def main():\n",
    "    data = build_linear_dataset(N)\n",
    "    x_data = data[:, :-1]\n",
    "    y_data = data[:, -1]\n",
    "    for j in range(num_iterations):\n",
    "        # run the model forward on the data\n",
    "        y_pred = regression_model(x_data).squeeze(-1)\n",
    "        # calculate the mse loss\n",
    "        loss = loss_fn(y_pred, y_data)\n",
    "        # initialize gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # take a gradient step\n",
    "        optim.step()\n",
    "        if (j + 1) % 500 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "    # Inspect learned parameters\n",
    "    print(\"Learned parameters:\")\n",
    "    for name, param in regression_model.named_parameters():\n",
    "        print(\"%s: %.3f\" % (name, param.data.numpy()))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = torch.zeros(1, 1)\n",
    "scale = torch.ones(1, 1)\n",
    "# define a unit normal prior\n",
    "prior = Normal(loc, scale)\n",
    "# overload the parameters in the regression module with samples from the prior\n",
    "lifted_module = pyro.random_module(\"regression_module\", regression_model, prior)\n",
    "# sample a regressor from the prior\n",
    "sampled_reg_model = lifted_module()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4003,  2.2615],\n",
       "        [ 0.4005,  2.1725],\n",
       "        [ 0.6008,  3.1805],\n",
       "        ...,\n",
       "        [ 0.1380,  1.0328],\n",
       "        [ 0.3884,  3.2729],\n",
       "        [ 0.0751,  1.3887]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = build_linear_dataset(N)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  model (data):\n",
    "    # Create unit normal priors over the parameters# Creat \n",
    "    loc, scale = torch.zeros(1, 1), 10 * torch.ones(1, 1)\n",
    "    bias_loc, bias_scale = torch.zeros(1), 10 * torch.ones(1)\n",
    "    w_prior = Normal(loc, scale).independent(1)\n",
    "    b_prior = Normal(bias_loc, bias_scale).independent(1)\n",
    "    priors = {'linear.weight': w_prior, 'linear.bias': b_prior}\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", regression_model, priors)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    lifted_reg_model = lifted_module()\n",
    "    with pyro.iarange(\"map\", N):\n",
    "        x_data = data[:, :-1]\n",
    "        y_data = data[:, -1]\n",
    "    \n",
    "        # run the regressor forward conditioned on data\n",
    "        prediction_mean = lifted_reg_model(x_data).squeeze(-1)\n",
    "        # condition on the observed data\n",
    "        pyro.sample(\"obs\", \n",
    "                    Normal(prediction_mean, 0.1 * torch.ones(data.size(0))),\n",
    "                    obs=y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define approximate model to perform variational inference with\n",
    "softplus = torch.nn.Softplus()\n",
    "\n",
    "def guide(data):\n",
    "    # define our variational parameters\n",
    "    w_loc = torch.randn(1, 1)\n",
    "    # note that we initialize our scales to be pretty narrow\n",
    "    w_log_sig = torch.tensor(-3.0 * torch.ones(1, 1) + 0.05 * torch.randn(1, 1))\n",
    "    b_loc = torch.randn(1)\n",
    "    b_log_sig = torch.tensor(-3.0 * torch.ones(1) + 0.05 * torch.randn(1))\n",
    "    # register learnable params in the param store\n",
    "    mw_param = pyro.param(\"guide_mean_weight\", w_loc)\n",
    "    sw_param = softplus(pyro.param(\"guide_log_scale_weight\", w_log_sig))\n",
    "    mb_param = pyro.param(\"guide_mean_bias\", b_loc)\n",
    "    sb_param = softplus(pyro.param(\"guide_log_scale_bias\", b_log_sig))\n",
    "    # guide distributions for w and b\n",
    "    w_dist = Normal(mw_param, sw_param).independent(1)\n",
    "    b_dist = Normal(mb_param, sb_param).independent(1)\n",
    "    dists = {'linear.weight': w_dist, 'linear.bias': b_dist}\n",
    "    # overload the parameters in the module with random samples \n",
    "    # from the guide distributions\n",
    "    lifted_module = pyro.random_module(\"module\", regression_model, dists)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    return lifted_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim = Adam({\"lr\": 0.05})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 628.2576\n",
      "[iteration 0101] loss: 10.8955\n",
      "[iteration 0201] loss: 10.9048\n",
      "[iteration 0301] loss: 10.8735\n",
      "[iteration 0401] loss: 10.8955\n",
      "[iteration 0501] loss: 10.8400\n",
      "[iteration 0601] loss: 10.9076\n",
      "[iteration 0701] loss: 10.8670\n",
      "[iteration 0801] loss: 10.8389\n",
      "[iteration 0901] loss: 10.8403\n"
     ]
    }
   ],
   "source": [
    "def  main():\n",
    "    pyro.clear_param_store()\n",
    "    data = build_linear_dataset(N)\n",
    "    for j in range(num_iterations):\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss = svi.step(data)\n",
    "        if j % 100 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / float(N)))\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[guide_mean_weight]: 3.010\n",
      "[guide_log_scale_weight]: -4.091\n",
      "[guide_mean_bias]: 0.987\n",
      "[guide_log_scale_bias]: -4.425\n"
     ]
    }
   ],
   "source": [
    "for name in pyro.get_param_store().get_all_param_names():\n",
    "    print(\"[%s]: %.3f\" % (name, pyro.param(name).data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1b169208>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1b19f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean = pyro.param('guide_mean_weight').data.numpy()\n",
    "logsd =pyro.param('guide_log_scale_weight').data.numpy()\n",
    "\n",
    "sd = np.exp(logsd)\n",
    "w = np.random.normal(mean[0] , sd[0] , 1000 )\n",
    "\n",
    "sns.distplot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.26525819301605225\n"
     ]
    }
   ],
   "source": [
    "X  =  np.linspace(6, 7, num=20)\n",
    "y = 3 * X + 1\n",
    "X, y = X.reshape((20, 1)), y.reshape((20, 1))\n",
    "x_data, y_data = torch.tensor(X).type(torch.Tensor), torch.tensor(y).type(torch.Tensor)\n",
    "loss = nn.MSELoss()\n",
    "y_preds = torch.zeros(20, 1)\n",
    "for i in range(20):\n",
    "    # guide does not require the data\n",
    "    sampled_reg_model = guide(None)\n",
    "    # run the regression model and add prediction to total\n",
    "    y_preds = y_preds + sampled_reg_model(x_data)\n",
    "# take the average of the predictions\n",
    "y_preds = y_preds / 20\n",
    "print (\"Loss: \", loss(y_preds, y_data).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
