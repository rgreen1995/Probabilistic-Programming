{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pyro\n",
    "from pyro.distributions import Normal\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "# for CI testing\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 10000  # size of toy data\n",
    "\n",
    "def build_linear_dataset(N, p=1, noise_std=0.5):\n",
    "    X = np.random.rand(N, p)\n",
    "    # w = 3\n",
    "    w = 3 * np.ones(p)\n",
    "    # b = 1\n",
    "    y = np.matmul(X, w) + np.repeat(1, N) + np.random.normal(0, noise_std, size=N)\n",
    "    y = y.reshape(N, 1)\n",
    "    X, y = torch.tensor(X).type(torch.Tensor), torch.tensor(y).type(torch.Tensor)\n",
    "    data = torch.cat((X, y), 1)\n",
    "    assert data.shape == (N, p + 1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = build_linear_dataset(N)\n",
    "data.shape\n",
    "#plt.plot(data.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class  RegressionModel(nn.Module):\n",
    "    def __init__(self, p):\n",
    "        # p = number of features\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(p, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "regression_model = RegressionModel(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0050] loss: 3173.6257\n",
      "[iteration 0100] loss: 2688.3459\n",
      "[iteration 0150] loss: 2523.6218\n",
      "[iteration 0200] loss: 2489.5234\n",
      "[iteration 0250] loss: 2485.0623\n",
      "[iteration 0300] loss: 2484.6809\n",
      "[iteration 0350] loss: 2484.6765\n",
      "[iteration 0400] loss: 2484.6633\n",
      "[iteration 0450] loss: 2484.6689\n",
      "[iteration 0500] loss: 2484.6680\n",
      "[iteration 0550] loss: 2484.6680\n",
      "[iteration 0600] loss: 2484.6680\n",
      "[iteration 0650] loss: 2484.6680\n",
      "[iteration 0700] loss: 2484.6677\n",
      "[iteration 0750] loss: 2484.6677\n",
      "[iteration 0800] loss: 2484.6677\n",
      "[iteration 0850] loss: 2484.6677\n",
      "[iteration 0900] loss: 2484.6677\n",
      "[iteration 0950] loss: 2484.6677\n",
      "[iteration 1000] loss: 2484.6677\n",
      "Learned parameters:\n",
      "linear.weight: 3.035\n",
      "linear.bias: 0.988\n"
     ]
    }
   ],
   "source": [
    "loss_fn = torch.nn.MSELoss(size_average=False)\n",
    "optim = torch.optim.Adam(regression_model.parameters(), lr=0.05)\n",
    "num_iterations = 1000 if not smoke_test else 2\n",
    "\n",
    "def main():\n",
    "    data = build_linear_dataset(N)\n",
    "    x_data = data[:, :-1]\n",
    "    y_data = data[:, -1]\n",
    "    for j in range(num_iterations):\n",
    "        # run the model forward on the data\n",
    "        y_pred = regression_model(x_data).squeeze(-1)\n",
    "        # calculate the mse loss\n",
    "        loss = loss_fn(y_pred, y_data)\n",
    "        # initialize gradients to zero\n",
    "        optim.zero_grad()\n",
    "        # backpropagate\n",
    "        loss.backward()\n",
    "        # take a gradient step\n",
    "        optim.step()\n",
    "        if (j + 1) % 50 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss.item()))\n",
    "    # Inspect learned parameters\n",
    "    print(\"Learned parameters:\")\n",
    "    for name, param in regression_model.named_parameters():\n",
    "        print(\"%s: %.3f\" % (name, param.data.numpy()))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loc = torch.zeros(1, 1)\n",
    "scale = torch.ones(1, 1)\n",
    "# define a unit normal prior\n",
    "prior = Normal(loc, scale)\n",
    "# overload the parameters in the regression module with samples from the prior\n",
    "lifted_module = pyro.random_module(\"regression_module\", regression_model, prior)\n",
    "# sample a regressor from the prior\n",
    "sampled_reg_model = lifted_module()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4003,  2.2615],\n",
       "        [ 0.4005,  2.1725],\n",
       "        [ 0.6008,  3.1805],\n",
       "        ...,\n",
       "        [ 0.1380,  1.0328],\n",
       "        [ 0.3884,  3.2729],\n",
       "        [ 0.0751,  1.3887]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = build_linear_dataset(N)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def  model (data):\n",
    "    # Create unit normal priors over the parameters# Creat \n",
    "    loc, scale = torch.zeros(1, 1), 10 * torch.ones(1, 1)\n",
    "    bias_loc, bias_scale = torch.zeros(1), 10 * torch.ones(1)\n",
    "    w_prior = Normal(loc, scale).independent(1)\n",
    "    b_prior = Normal(bias_loc, bias_scale).independent(1)\n",
    "    priors = {'linear.weight': w_prior, 'linear.bias': b_prior}\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", regression_model, priors)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    lifted_reg_model = lifted_module()\n",
    "    with pyro.iarange(\"map\", N):\n",
    "        x_data = data[:, :-1]\n",
    "        y_data = data[:, -1]\n",
    "    \n",
    "        # run the regressor forward conditioned on data\n",
    "        prediction_mean = lifted_reg_model(x_data).squeeze(-1)\n",
    "        # condition on the observed data\n",
    "        pyro.sample(\"obs\", \n",
    "                    Normal(prediction_mean, 0.1 * torch.ones(data.size(0))),\n",
    "                    obs=y_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Define approximate model to perform variational inference with\n",
    "softplus = torch.nn.Softplus()\n",
    "\n",
    "def guide(data):\n",
    "    # define our variational parameters\n",
    "    w_loc = torch.randn(1, 1)\n",
    "    # note that we initialize our scales to be pretty narrow\n",
    "    w_log_sig = torch.tensor(-3.0 * torch.ones(1, 1) + 0.05 * torch.randn(1, 1))\n",
    "    b_loc = torch.randn(1)\n",
    "    b_log_sig = torch.tensor(-3.0 * torch.ones(1) + 0.05 * torch.randn(1))\n",
    "    # register learnable params in the param store\n",
    "    mw_param = pyro.param(\"guide_mean_weight\", w_loc)\n",
    "    sw_param = softplus(pyro.param(\"guide_log_scale_weight\", w_log_sig))\n",
    "    mb_param = pyro.param(\"guide_mean_bias\", b_loc)\n",
    "    sb_param = softplus(pyro.param(\"guide_log_scale_bias\", b_log_sig))\n",
    "    # guide distributions for w and b\n",
    "    w_dist = Normal(mw_param, sw_param).independent(1)\n",
    "    b_dist = Normal(mb_param, sb_param).independent(1)\n",
    "    dists = {'linear.weight': w_dist, 'linear.bias': b_dist}\n",
    "    # overload the parameters in the module with random samples \n",
    "    # from the guide distributions\n",
    "    lifted_module = pyro.random_module(\"module\", regression_model, dists)\n",
    "    # sample a regressor (which also samples w and b)\n",
    "    return lifted_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optim = Adam({\"lr\": 0.05})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 628.2576\n",
      "[iteration 0101] loss: 10.8955\n",
      "[iteration 0201] loss: 10.9048\n",
      "[iteration 0301] loss: 10.8735\n",
      "[iteration 0401] loss: 10.8955\n",
      "[iteration 0501] loss: 10.8400\n",
      "[iteration 0601] loss: 10.9076\n",
      "[iteration 0701] loss: 10.8670\n",
      "[iteration 0801] loss: 10.8389\n",
      "[iteration 0901] loss: 10.8403\n"
     ]
    }
   ],
   "source": [
    "def  main():\n",
    "    pyro.clear_param_store()\n",
    "    data = build_linear_dataset(N)\n",
    "    for j in range(num_iterations):\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss = svi.step(data)\n",
    "        if j % 100 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss / float(N)))\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[guide_mean_weight]: 3.010\n",
      "[guide_log_scale_weight]: -4.091\n",
      "[guide_mean_bias]: 0.987\n",
      "[guide_log_scale_bias]: -4.425\n"
     ]
    }
   ],
   "source": [
    "for name in pyro.get_param_store().get_all_param_names():\n",
    "    print(\"[%s]: %.3f\" % (name, pyro.param(name).data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1b169208>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1b19f1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mean = pyro.param('guide_mean_weight').data.numpy()\n",
    "logsd =pyro.param('guide_log_scale_weight').data.numpy()\n",
    "\n",
    "sd = np.exp(logsd)\n",
    "w = np.random.normal(mean[0] , sd[0] , 1000 )\n",
    "\n",
    "sns.distplot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.26525819301605225\n"
     ]
    }
   ],
   "source": [
    "X  =  np.linspace(6, 7, num=20)\n",
    "y = 3 * X + 1\n",
    "X, y = X.reshape((20, 1)), y.reshape((20, 1))\n",
    "x_data, y_data = torch.tensor(X).type(torch.Tensor), torch.tensor(y).type(torch.Tensor)\n",
    "loss = nn.MSELoss()\n",
    "y_preds = torch.zeros(20, 1)\n",
    "for i in range(20):\n",
    "    # guide does not require the data\n",
    "    sampled_reg_model = guide(None)\n",
    "    # run the regression model and add prediction to total\n",
    "    y_preds = y_preds + sampled_reg_model(x_data)\n",
    "# take the average of the predictions\n",
    "y_preds = y_preds / 20\n",
    "print (\"Loss: \", loss(y_preds, y_data).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
